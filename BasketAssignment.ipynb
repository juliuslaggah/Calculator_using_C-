{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juliuslaggah/Calculator_using_C-/blob/main/BasketAssignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1i8DOL75mV3"
      },
      "outputs": [],
      "source": [
        "!pip install mlxtend\n",
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "from mlxtend.preprocessing import TransactionEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1HaUOUpD8N-"
      },
      "source": [
        "1. Uploading the Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JARSUY5iD9Tw"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0mR8H_6EIwa"
      },
      "source": [
        "2. Loading and Exploring the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkHB3VrUEJzM"
      },
      "outputs": [],
      "source": [
        "# Count the number of transactions in Sales1998.txt\n",
        "with open('Sales1998.txt', 'r') as f:\n",
        "    transactions = f.readlines()\n",
        "\n",
        "print(\"Number of transactions in Sales1998.txt:\", len(transactions))\n",
        "\n",
        "# Process each line in productList.txt to build product_dict\n",
        "product_lines = []\n",
        "with open('productList.txt', 'r') as f:\n",
        "    product_lines = f.readlines()\n",
        "\n",
        "# Use regex to extract product ID and name\n",
        "import re\n",
        "product_dict = {}\n",
        "for line in product_lines:\n",
        "    match = re.match(r'(\\d+)\\s+\"(.+)\"', line.strip())\n",
        "    if match:\n",
        "        prod_id = match.group(1)\n",
        "        prod_name = match.group(2)\n",
        "        product_dict[prod_id] = prod_name\n",
        "\n",
        "print(\"Number of products in productList.txt:\", len(product_dict))\n",
        "\n",
        "# Optional: Preview a few mappings\n",
        "print(\"\\nSample Product Mappings:\")\n",
        "for pid, pname in list(product_dict.items())[:10]:\n",
        "    print(f\"{pid}: {pname}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0aI2RnoEW04"
      },
      "source": [
        "3. Preparing the Transactions Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4LYl_QJEc3n"
      },
      "outputs": [],
      "source": [
        "\n",
        "transactions_split = [line.strip().split() for line in transactions]\n",
        "print(\"Example transaction (product IDs):\", transactions_split[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uX7WaM4VErL1"
      },
      "outputs": [],
      "source": [
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "import pandas as pd\n",
        "transactions_split = [line.strip().split() for line in transactions]\n",
        "transactions_named = [\n",
        "    [product_dict.get(pid, f\"Unknown_{pid}\") for pid in basket]\n",
        "    for basket in transactions_split\n",
        "]\n",
        "\n",
        "# Encode transactions with product names\n",
        "te = TransactionEncoder()\n",
        "te_array = te.fit(transactions_named).transform(transactions_named)\n",
        "df = pd.DataFrame(te_array, columns=te.columns_)\n",
        "print(\"One-hot encoded transaction sample:\")\n",
        "print(df.head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLkat102JEAR"
      },
      "source": [
        "4. Applying the FP-Growth Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZRtVb6zJHtJ"
      },
      "outputs": [],
      "source": [
        "from mlxtend.frequent_patterns import fpgrowth\n",
        "frequent_itemsets_fp = fpgrowth(df, min_support=0.0001, use_colnames=True)\n",
        "frequent_itemsets_fp['item_count'] = frequent_itemsets_fp['itemsets'].apply(lambda x: len(x))\n",
        "multi_itemsets = frequent_itemsets_fp[frequent_itemsets_fp['item_count'] > 1].copy()\n",
        "multi_itemsets['itemsets'] = multi_itemsets['itemsets'].apply(lambda x: ', '.join(x))\n",
        "print(f\"Total Multi-Item Frequent Itemsets Found: {len(multi_itemsets)}\")\n",
        "print(multi_itemsets[['support', 'itemsets']].head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTB7Sg5_NIaX"
      },
      "source": [
        "5. Generating Association Rules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOjcoX8TNLyl",
        "outputId": "d1fe4b0a-61dc-4f36-a54f-db3f35910140"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total Association Rules Found: 6421\n",
            "\n",
            "Top 20 Association Rules in Plain Language:\n",
            "\n",
            "If a customer buys [Super Creamy Peanut Butter, Ebony Garlic], they are also likely to buy [Faux Products Silky Smooth Hair Conditioner].\n",
            "  - Support: 0.0001, Confidence: 1.00, Lift: 448.29\n",
            "\n",
            "If a customer buys [Golden Frozen Mushroom Pizza, Lake Low Fat Cole Slaw], they are also likely to buy [Club Low Fat Cottage Cheese].\n",
            "  - Support: 0.0001, Confidence: 1.00, Lift: 370.33\n",
            "\n",
            "If a customer buys [Lake Low Fat Cole Slaw, Club Low Fat Cottage Cheese], they are also likely to buy [Golden Frozen Mushroom Pizza].\n",
            "  - Support: 0.0001, Confidence: 1.00, Lift: 306.94\n",
            "\n",
            "If a customer buys [Gulf Coast White Chocolate Bar, American Corned Beef], they are also likely to buy [High Top Garlic].\n",
            "  - Support: 0.0001, Confidence: 1.00, Lift: 330.78\n",
            "\n",
            "If a customer buys [Thresher Mint Chocolate Bar, Big Time Popsicles], they are also likely to buy [Bravo Canned Tuna in Oil].\n",
            "  - Support: 0.0001, Confidence: 1.00, Lift: 324.48\n",
            "\n",
            "If a customer buys [Bravo Canned Tuna in Oil, Thresher Mint Chocolate Bar], they are also likely to buy [Big Time Popsicles].\n",
            "  - Support: 0.0001, Confidence: 1.00, Lift: 315.46\n",
            "\n",
            "If a customer buys [Thresher Mint Chocolate Bar, High Top Prepared Salad, Big Time Popsicles], they are also likely to buy [Bravo Canned Tuna in Oil].\n",
            "  - Support: 0.0001, Confidence: 1.00, Lift: 324.48\n",
            "\n",
            "If a customer buys [Thresher Mint Chocolate Bar, Bravo Canned Tuna in Oil, Big Time Popsicles], they are also likely to buy [High Top Prepared Salad].\n",
            "  - Support: 0.0001, Confidence: 1.00, Lift: 334.02\n",
            "\n",
            "If a customer buys [High Top Prepared Salad, Bravo Canned Tuna in Oil, Thresher Mint Chocolate Bar], they are also likely to buy [Big Time Popsicles].\n",
            "  - Support: 0.0001, Confidence: 1.00, Lift: 315.46\n",
            "\n",
            "If a customer buys [Thresher Mint Chocolate Bar, Big Time Popsicles], they are also likely to buy [High Top Prepared Salad, Bravo Canned Tuna in Oil].\n",
            "  - Support: 0.0001, Confidence: 1.00, Lift: 6814.00\n",
            "\n",
            "If a customer buys [Bravo Canned Tuna in Oil, Thresher Mint Chocolate Bar], they are also likely to buy [High Top Prepared Salad, Big Time Popsicles].\n",
            "  - Support: 0.0001, Confidence: 1.00, Lift: 6814.00\n",
            "\n",
            "If a customer buys [Imagine Lime Popsicles, High Top Peaches], they are also likely to buy [Super Oregano].\n",
            "  - Support: 0.0001, Confidence: 1.00, Lift: 330.78\n",
            "\n",
            "If a customer buys [Best Choice Salsa Dip, Denny 25 Watt Lightbulb], they are also likely to buy [Denny Scissors, Nationeel Lemon Cookies].\n",
            "  - Support: 0.0001, Confidence: 1.00, Lift: 8517.50\n",
            "\n",
            "If a customer buys [Denny Scissors, Nationeel Lemon Cookies], they are also likely to buy [Denny 25 Watt Lightbulb].\n",
            "  - Support: 0.0001, Confidence: 1.00, Lift: 318.41\n",
            "\n",
            "If a customer buys [Best Choice Salsa Dip, Denny 25 Watt Lightbulb], they are also likely to buy [Nationeel Lemon Cookies].\n",
            "  - Support: 0.0001, Confidence: 1.00, Lift: 286.30\n",
            "\n",
            "If a customer buys [Denny Scissors, Best Choice Salsa Dip], they are also likely to buy [Denny 25 Watt Lightbulb].\n",
            "  - Support: 0.0001, Confidence: 1.00, Lift: 318.41\n",
            "\n",
            "If a customer buys [Best Choice Salsa Dip, Denny 25 Watt Lightbulb], they are also likely to buy [Denny Scissors].\n",
            "  - Support: 0.0001, Confidence: 1.00, Lift: 315.46\n",
            "\n",
            "If a customer buys [Denny Scissors, Nationeel Lemon Cookies, Best Choice Salsa Dip], they are also likely to buy [Denny 25 Watt Lightbulb].\n",
            "  - Support: 0.0001, Confidence: 1.00, Lift: 318.41\n",
            "\n",
            "If a customer buys [Denny Scissors, Nationeel Lemon Cookies, Denny 25 Watt Lightbulb], they are also likely to buy [Best Choice Salsa Dip].\n",
            "  - Support: 0.0001, Confidence: 1.00, Lift: 268.27\n",
            "\n",
            "If a customer buys [Denny Scissors, Best Choice Salsa Dip, Denny 25 Watt Lightbulb], they are also likely to buy [Nationeel Lemon Cookies].\n",
            "  - Support: 0.0001, Confidence: 1.00, Lift: 286.30\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from mlxtend.frequent_patterns import association_rules\n",
        "\n",
        "# Generate association rules\n",
        "rules_fp = association_rules(frequent_itemsets_fp, metric=\"confidence\", min_threshold=0.05)\n",
        "\n",
        "# Convert frozen sets to readable strings\n",
        "rules_fp['antecedents'] = rules_fp['antecedents'].apply(lambda x: list(x))\n",
        "rules_fp['consequents'] = rules_fp['consequents'].apply(lambda x: list(x))\n",
        "\n",
        "# Sort by confidence\n",
        "rules_fp_sorted = rules_fp.sort_values(by='confidence', ascending=False)\n",
        "\n",
        "# Display top 10 rules in plain language\n",
        "print(f\"\\nTotal Association Rules Found: {len(rules_fp_sorted)}\")\n",
        "print(\"\\nTop 20 Association Rules in Plain Language:\\n\")\n",
        "for idx, row in rules_fp_sorted.head(20).iterrows():\n",
        "    antecedents = ', '.join(row['antecedents'])\n",
        "    consequents = ', '.join(row['consequents'])\n",
        "    print(f\"If a customer buys [{antecedents}], they are also likely to buy [{consequents}].\")\n",
        "    print(f\"  - Support: {row['support']:.4f}, Confidence: {row['confidence']:.2f}, Lift: {row['lift']:.2f}\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOeDXg3XBqNHfZ95q9FkLzR",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}